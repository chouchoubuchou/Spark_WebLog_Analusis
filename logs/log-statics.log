2018-11-28 00:06:37,674-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:06:38,156-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:06:43,346-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:06:43,368-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:06:43,369-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:06:43,369-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:06:43,370-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:06:43,370-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:06:43,754-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 49844.
2018-11-28 00:06:43,780-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:06:43,805-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:06:43,810-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:06:43,810-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:06:43,821-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6b2ff429-316c-4ff3-98ac-967981736283
2018-11-28 00:06:43,877-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:06:43,933-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:06:44,045-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @7118ms
2018-11-28 00:06:44,179-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:06:44,199-[TS] INFO main org.spark_project.jetty.server.Server - Started @7273ms
2018-11-28 00:06:44,226-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@739db583{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:06:44,226-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:06:44,248-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,249-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,249-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,250-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,251-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,252-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,253-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,255-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,256-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,257-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,258-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,259-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,260-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,261-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,262-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,262-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,263-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,264-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,265-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,266-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,275-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,276-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,277-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,278-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,279-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:06:44,281-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:06:44,373-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:06:44,392-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49845.
2018-11-28 00:06:44,393-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:49845
2018-11-28 00:06:44,394-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:06:44,421-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 49845, None)
2018-11-28 00:06:44,425-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:49845 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 49845, None)
2018-11-28 00:06:44,428-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 49845, None)
2018-11-28 00:06:44,428-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 49845, None)
2018-11-28 00:06:44,643-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:46,200-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:06:46,201-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:06:46,209-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:06:46,209-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:46,210-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:06:46,211-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:06:46,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:06:46,763-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:06:47,009-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:06:47,343-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:06:47,355-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:08:09,408 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:08:09,408-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:08:09,828 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:08:09,828-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:08:14,981 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:08:14,981-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:08:14,997 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:08:14,997-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:08:14,997 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:08:14,997-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:08:14,997 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:08:14,997-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:08:14,998 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:08:14,998-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:08:14,998 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:08:14,998-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:08:15,234 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 49883.
2018-11-28 00:08:15,234-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 49883.
2018-11-28 00:08:15,250 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:08:15,250-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:08:15,264 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:08:15,264-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:08:15,266 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:08:15,266-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:08:15,266 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:08:15,266-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:08:15,273 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-f4f24954-0e46-4c92-a2e4-0b581a14bae1
2018-11-28 00:08:15,273-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-f4f24954-0e46-4c92-a2e4-0b581a14bae1
2018-11-28 00:08:15,314 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:08:15,314-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:08:15,354 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:08:15,354-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:08:15,421 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6682ms
2018-11-28 00:08:15,421-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6682ms
2018-11-28 00:08:15,471 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:08:15,471-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:08:15,484 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6746ms
2018-11-28 00:08:15,484-[TS] INFO main org.spark_project.jetty.server.Server - Started @6746ms
2018-11-28 00:08:15,500 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@28e731cf{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:08:15,500-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@28e731cf{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:08:15,501 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:08:15,501-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:08:15,523 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,523-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,524 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,524-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,525 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,525-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,526 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,526-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,527 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,527-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,529 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,529-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,529 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,529-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,531 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,531-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,532 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,532-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,532 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,532-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,533 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,533-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,534 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,534-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,535 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,535-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,536 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,536-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,536 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,536-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,537 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,537-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,538 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,538-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,539 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,539-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,540 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,540-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,541 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,541-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,549 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,549-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,550 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,550-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,552 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,552-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,553 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,553-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,554 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,554-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,556 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:08:15,556-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:08:15,627 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:08:15,627-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:08:15,643 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49885.
2018-11-28 00:08:15,643-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49885.
2018-11-28 00:08:15,644 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:49885
2018-11-28 00:08:15,644-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:49885
2018-11-28 00:08:15,645 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:08:15,645-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:08:15,663 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,663-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,666 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:49885 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,666-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:49885 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,668 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,668-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,668 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,668-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 49885, None)
2018-11-28 00:08:15,828 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:15,828-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,278 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:08:17,278-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:08:17,279 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:08:17,279-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:08:17,286 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,286-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,287 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,287-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,287 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,287-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,288 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,288-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,289 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,289-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:08:17,711 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:08:17,711-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:08:17,870 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:08:17,870-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:08:18,131 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:08:18,131-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:08:18,144 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:08:18,144-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:10:54,289 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:10:54,289-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:10:54,737 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:10:54,737-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:10:59,881 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:10:59,881-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:10:59,895 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:10:59,895-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:10:59,896 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:10:59,896-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:10:59,896 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:10:59,896-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:10:59,897 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:10:59,897-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:10:59,897 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:10:59,897-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:11:00,117 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 49963.
2018-11-28 00:11:00,117-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 49963.
2018-11-28 00:11:00,132 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:11:00,132-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:11:00,146 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:11:00,146-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:11:00,148 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:11:00,148-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:11:00,148 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:11:00,148-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:11:00,154 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-e83756a1-7709-4593-bf81-f5548e39ae7f
2018-11-28 00:11:00,154-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-e83756a1-7709-4593-bf81-f5548e39ae7f
2018-11-28 00:11:00,193 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:11:00,193-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:11:00,233 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:11:00,233-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:11:00,297 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6707ms
2018-11-28 00:11:00,297-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6707ms
2018-11-28 00:11:00,342 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:11:00,342-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:11:00,354 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6765ms
2018-11-28 00:11:00,354-[TS] INFO main org.spark_project.jetty.server.Server - Started @6765ms
2018-11-28 00:11:00,370 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@4c9da3d7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:11:00,370-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@4c9da3d7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:11:00,371 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:11:00,371-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:11:00,394 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,394-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,395 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,395-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,396 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,396-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,397 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,397-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,398 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,398-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,398 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,398-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,399 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,399-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,400 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,400-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,401 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,401-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,402 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,402-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,403 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,403-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,403 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,403-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,405 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,405-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,406 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,406-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,407 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,407-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,408 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,408-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,409 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,409-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,410 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,410-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,411 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,411-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,412 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,412-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,420 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,420-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,421 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,421-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,423 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,423-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,424 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,424-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,426 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,426-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,429 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:11:00,429-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:11:00,501 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:11:00,501-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:11:00,517 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49964.
2018-11-28 00:11:00,517-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49964.
2018-11-28 00:11:00,518 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:49964
2018-11-28 00:11:00,518-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:49964
2018-11-28 00:11:00,519 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:11:00,519-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:11:00,536 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,536-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,539 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:49964 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,539-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:49964 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,541 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,541-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,541 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,541-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 49964, None)
2018-11-28 00:11:00,707 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:00,707-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,061 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:11:02,061-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:11:02,062 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:11:02,062-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:11:02,067 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,067-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,067 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,067-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,068 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,068-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,069 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,069-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,070 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,070-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:11:02,445 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:11:02,445-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:11:02,586 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:11:02,586-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:11:02,820 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:11:02,820-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:11:02,831 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:11:02,831-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:14:36,618 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:14:36,618-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:14:37,074 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:14:37,074-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:14:42,238 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:14:42,238-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:14:42,254 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:14:42,254-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:14:42,255 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:14:42,255-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:14:42,255 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:14:42,255-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:14:42,256 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:14:42,256-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:14:42,256 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:14:42,256-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:14:42,497 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 50011.
2018-11-28 00:14:42,497-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50011.
2018-11-28 00:14:42,512 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:14:42,512-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:14:42,526 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:14:42,526-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:14:42,528 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:14:42,528-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:14:42,528 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:14:42,528-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:14:42,535 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-49101f4a-6739-4e19-b53b-3844a45c9132
2018-11-28 00:14:42,535-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-49101f4a-6739-4e19-b53b-3844a45c9132
2018-11-28 00:14:42,582 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:14:42,582-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:14:42,642 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:14:42,642-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:14:42,735 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6791ms
2018-11-28 00:14:42,735-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6791ms
2018-11-28 00:14:42,809 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:14:42,809-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:14:42,825 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6882ms
2018-11-28 00:14:42,825-[TS] INFO main org.spark_project.jetty.server.Server - Started @6882ms
2018-11-28 00:14:42,845 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@37ebc9d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:14:42,845-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@37ebc9d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:14:42,845 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:14:42,845-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:14:42,879 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,879-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,881 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cc76301{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,881-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cc76301{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,882 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,882-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,884 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,884-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,887 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,887-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,888 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,888-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,890 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,890-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,894 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,894-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,895 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,895-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,898 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,898-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,899 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,899-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,902 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,902-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,903 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,903-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,904 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,904-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,906 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,906-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,907 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,907-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,910 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,910-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,911 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,911-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,914 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,914-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,915 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,915-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,927 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/static,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,927-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/static,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,929 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1133ec6e{/,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,929-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1133ec6e{/,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,931 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/api,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,931-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/api,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,932 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@48c40605{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,932-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48c40605{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,933 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,933-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:14:42,936 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:14:42,936-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:14:43,077 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:14:43,077-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:14:43,099 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50012.
2018-11-28 00:14:43,099-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50012.
2018-11-28 00:14:43,100 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:50012
2018-11-28 00:14:43,100-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:50012
2018-11-28 00:14:43,102 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:14:43,102-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:14:43,125 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,125-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,128 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:50012 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,128-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:50012 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,131 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,131-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,131 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,131-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50012, None)
2018-11-28 00:14:43,349 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@408a247c{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:43,349-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@408a247c{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,788 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:14:44,788-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:14:44,790 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:14:44,790-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:14:44,795 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,795-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,795 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,795-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,796 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,796-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,797 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,797-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,798 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:14:44,798-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:14:45,191 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:14:45,191-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:14:45,331 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:14:45,331-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:14:45,561 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:14:45,561-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:14:45,572 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:14:45,572-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:16:11,118 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:16:11,118-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:16:11,541 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:16:11,541-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:16:16,700 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:16:16,700-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:16:16,717 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:16:16,717-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:16:16,717 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:16:16,717-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:16:16,718 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:16:16,718-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:16:16,718 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:16:16,718-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:16:16,718 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:16:16,718-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:16:16,934 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 50076.
2018-11-28 00:16:16,934-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50076.
2018-11-28 00:16:16,948 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:16:16,948-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:16:16,961 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:16:16,961-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:16:16,963 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:16:16,963-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:16:16,963 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:16:16,963-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:16:16,969 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-a7e3f86f-09e2-40ad-b896-c8c05a088af1
2018-11-28 00:16:16,969-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-a7e3f86f-09e2-40ad-b896-c8c05a088af1
2018-11-28 00:16:17,009 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:16:17,009-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:16:17,051 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:16:17,051-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:16:17,118 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6683ms
2018-11-28 00:16:17,118-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6683ms
2018-11-28 00:16:17,166 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:16:17,166-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:16:17,178 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6744ms
2018-11-28 00:16:17,178-[TS] INFO main org.spark_project.jetty.server.Server - Started @6744ms
2018-11-28 00:16:17,194 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2c85f3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:16:17,194-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2c85f3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:16:17,195 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:16:17,195-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:16:17,218 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,218-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,218 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cc76301{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,218-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cc76301{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,219 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,219-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,220 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,220-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,221 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,221-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,222 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,222-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,223 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,223-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,225 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,225-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,225 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,225-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,226 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,226-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,226 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,226-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,227 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,227-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,228 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,228-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,228 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,228-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,230 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,230-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,231 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,231-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,232 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,232-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,233 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,233-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,234 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,234-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,241 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/static,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,241-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/static,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,242 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1133ec6e{/,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,242-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1133ec6e{/,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,243 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/api,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,243-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/api,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,244 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@48c40605{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,244-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48c40605{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,245 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,245-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,247 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:16:17,247-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:16:17,319 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:16:17,319-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:16:17,336 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50077.
2018-11-28 00:16:17,336-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50077.
2018-11-28 00:16:17,336 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:50077
2018-11-28 00:16:17,336-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:50077
2018-11-28 00:16:17,337 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:16:17,337-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:16:17,355 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,355-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,358 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:50077 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,358-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:50077 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,360 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,360-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,360 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,360-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50077, None)
2018-11-28 00:16:17,529 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@408a247c{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:17,529-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@408a247c{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,876 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:16:18,876-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:16:18,879 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:16:18,879-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:16:18,884 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,884-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,885 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,885-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,885 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,885-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,886 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,886-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,887 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:16:18,887-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:16:19,260 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:16:19,260-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:16:19,422 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:16:19,422-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:16:19,656 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:16:19,656-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:16:19,670 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:16:19,670-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:17:32,517 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:17:32,517-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:17:32,935 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:17:32,935-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:17:38,077 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:17:38,077-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:17:38,094 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:17:38,094-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:17:38,094 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:17:38,094-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:17:38,095 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:17:38,095-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:17:38,095 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:17:38,095-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:17:38,096 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:17:38,096-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:17:38,334 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 50127.
2018-11-28 00:17:38,334-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50127.
2018-11-28 00:17:38,349 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:17:38,349-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:17:38,363 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:17:38,363-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:17:38,366 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:17:38,366-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:17:38,366 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:17:38,366-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:17:38,374 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-9d4786a5-5f4c-485c-8758-2dd97c2cf9db
2018-11-28 00:17:38,374-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-9d4786a5-5f4c-485c-8758-2dd97c2cf9db
2018-11-28 00:17:38,417 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:17:38,417-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:17:38,457 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:17:38,457-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:17:38,521 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6675ms
2018-11-28 00:17:38,521-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6675ms
2018-11-28 00:17:38,572 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:17:38,572-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:17:38,585 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6740ms
2018-11-28 00:17:38,585-[TS] INFO main org.spark_project.jetty.server.Server - Started @6740ms
2018-11-28 00:17:38,601 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@56b1dae0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:17:38,601-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@56b1dae0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:17:38,602 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:17:38,602-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:17:38,626 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,626-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,627 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,627-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,627 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,627-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,628 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,628-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,629 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,629-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,629 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,629-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,630 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,630-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,632 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,632-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,632 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,632-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,634 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,634-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,636 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,636-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,637 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,637-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,639 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,639-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,640 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,640-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,640 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,640-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,641 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,641-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,642 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,642-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,642 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,642-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,643 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,643-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,643 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,643-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,654 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,654-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,655 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,655-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,657 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,657-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,658 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,658-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,659 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,659-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,661 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:17:38,661-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:17:38,738 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:17:38,738-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:17:38,756 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50128.
2018-11-28 00:17:38,756-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50128.
2018-11-28 00:17:38,757 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:50128
2018-11-28 00:17:38,757-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:50128
2018-11-28 00:17:38,758 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:17:38,758-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:17:38,777 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,777-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,780 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:50128 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,780-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:50128 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,783 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,783-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,783 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,783-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50128, None)
2018-11-28 00:17:38,984 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:38,984-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,558 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:17:40,558-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:17:40,559 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:17:40,559-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:17:40,565 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,565-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,565 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,565-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,566 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,566-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,567 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,567-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,569 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:17:40,569-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:17:41,244 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:17:41,244-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:17:41,494 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:17:41,494-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:17:41,735 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:17:41,735-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:17:41,750 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:17:41,750-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:19:04,887 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:19:04,887-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:19:05,340 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:19:05,340-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:19:10,493 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:19:10,493-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:19:10,507 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:19:10,507-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:19:10,508 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:19:10,508-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:19:10,508 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:19:10,508-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:19:10,508 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:19:10,508-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:19:10,509 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:19:10,509-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:19:10,728 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 50157.
2018-11-28 00:19:10,728-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50157.
2018-11-28 00:19:10,742 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:19:10,742-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:19:10,755 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:19:10,755-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:19:10,757 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:19:10,757-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:19:10,758 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:19:10,758-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:19:10,764 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6115d226-a8fe-483b-adda-8865cc7402e0
2018-11-28 00:19:10,764-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-6115d226-a8fe-483b-adda-8865cc7402e0
2018-11-28 00:19:10,805 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:19:10,805-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:19:10,847 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:19:10,847-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:19:10,910 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6708ms
2018-11-28 00:19:10,910-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6708ms
2018-11-28 00:19:10,958 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:19:10,958-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:19:10,970 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6769ms
2018-11-28 00:19:10,970-[TS] INFO main org.spark_project.jetty.server.Server - Started @6769ms
2018-11-28 00:19:10,987 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@37ebc9d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:19:10,987-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@37ebc9d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:19:10,988 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:19:10,988-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:19:11,010 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,010-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@532a02d9{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,011 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4cc76301{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,011-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cc76301{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,012 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,012-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f19b8b3{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,013 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,013-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cdc3aae{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,014 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5dcbb60{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,014-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dcbb60{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,015 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21526f6c{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,015-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21526f6c{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,016 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@299266e2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,016-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@299266e2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,018 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,018-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,019 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,019-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,020 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,020-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@142eef62{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,021 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,021-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,021 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,021-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,022 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,022-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,023 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,023-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,024 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,024-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,024 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,024-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,025 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,025-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,026 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,026-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,026 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,026-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,027 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,027-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,035 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/static,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,035-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/static,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,036 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1133ec6e{/,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,036-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1133ec6e{/,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,038 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54709809{/api,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,038-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54709809{/api,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,038 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@48c40605{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,038-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48c40605{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,039 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b11ef33{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,039-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b11ef33{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,041 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:19:11,041-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:19:11,113 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:19:11,113-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:19:11,130 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50158.
2018-11-28 00:19:11,130-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50158.
2018-11-28 00:19:11,130 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:50158
2018-11-28 00:19:11,130-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:50158
2018-11-28 00:19:11,131 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:19:11,131-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:19:11,149 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,149-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,152 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:50158 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,152-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:50158 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,154 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,154-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,154 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,154-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50158, None)
2018-11-28 00:19:11,303 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@408a247c{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:11,303-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@408a247c{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,663 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:19:12,663-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:19:12,664 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:19:12,664-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:19:12,669 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,669-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,670 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,670-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,671 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,671-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,671 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,671-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,672 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:19:12,672-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:19:13,057 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:19:13,057-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:19:13,207 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:19:13,207-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:19:13,431 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:19:13,431-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:19:13,442 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:19:13,442-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:21:25,800 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 00:21:25,800-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 00:21:26,214 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:21:26,214-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 00:21:31,343 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 00:21:31,343-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 00:21:31,357 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 00:21:31,357-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 00:21:31,358 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 00:21:31,358-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 00:21:31,358 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 00:21:31,358-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 00:21:31,359 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 00:21:31,359-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 00:21:31,359 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:21:31,359-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 00:21:31,577 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 50220.
2018-11-28 00:21:31,577-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 50220.
2018-11-28 00:21:31,591 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 00:21:31,591-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 00:21:31,604 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 00:21:31,604-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 00:21:31,606 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:21:31,606-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 00:21:31,606 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 00:21:31,606-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 00:21:31,613 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-8c35623a-c8f2-4fbe-a269-48c456432bba
2018-11-28 00:21:31,613-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-8c35623a-c8f2-4fbe-a269-48c456432bba
2018-11-28 00:21:31,653 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:21:31,653-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 00:21:31,697 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 00:21:31,697-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 00:21:31,765 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6628ms
2018-11-28 00:21:31,765-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6628ms
2018-11-28 00:21:31,815 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 00:21:31,815-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 00:21:31,828 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6692ms
2018-11-28 00:21:31,828-[TS] INFO main org.spark_project.jetty.server.Server - Started @6692ms
2018-11-28 00:21:31,845 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@81810a1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:21:31,845-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@81810a1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 00:21:31,846 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:21:31,846-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 00:21:31,868 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,868-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@644c78d4{/jobs,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,869 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,869-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@372ea2bc{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,871 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,871-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f08c4b{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,872 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,872-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a486d78{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,872 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,872-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ef2d7a6{/stages,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,873 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,873-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c36250e{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,874 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,874-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@49f5c307{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,877 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,877-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1601e47{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,878 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,878-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,879 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,879-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,880 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,880-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/storage,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,881 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,881-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,882 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,882-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,883 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,883-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,884 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,884-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f415a95{/environment,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,885 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,885-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,886 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,886-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/executors,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,887 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,887-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,888 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,888-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,889 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,889-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,897 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,897-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/static,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,899 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,899-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6063d80a{/,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,901 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,901-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@355e34c7{/api,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,901 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,901-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@770d0ea6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,902 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,902-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54107f42{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 00:21:31,904 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:21:31,904-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 00:21:31,974 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 00:21:31,974-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 00:21:31,991 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50221.
2018-11-28 00:21:31,991-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50221.
2018-11-28 00:21:31,992 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:50221
2018-11-28 00:21:31,992-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:50221
2018-11-28 00:21:31,993 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:21:31,993-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 00:21:32,011 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,011-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,014 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:50221 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,014-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:50221 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,015 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,015-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,016 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,016-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 50221, None)
2018-11-28 00:21:32,178 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:32,178-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f63c44f{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,576 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:21:33,576-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 00:21:33,577 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:21:33,577-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 00:21:33,582 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,582-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,583 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,583-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,584 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,584-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,584 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,584-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,586 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,586-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 00:21:33,974 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 00:21:33,974-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 00:21:34,130 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 00:21:34,130-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 00:21:34,367 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 00:21:34,367-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 00:21:34,379 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 00:21:34,379-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 00:21:41,587 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (114 KB). The maximum recommended task size is 100 KB.
2018-11-28 00:21:41,587-[TS] WARN dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (114 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:00:57,712 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:00:57,712-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:00:58,180 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:00:58,180-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:01:03,381 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:01:03,381-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:01:03,404 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:01:03,404-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:01:03,405 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:01:03,405-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:01:03,405 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:01:03,405-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:01:03,405 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:01:03,405-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:01:03,406 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:01:03,406-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:01:03,755 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 52650.
2018-11-28 02:01:03,755-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52650.
2018-11-28 02:01:03,780 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:01:03,780-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:01:03,803 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:01:03,803-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:01:03,807 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:01:03,807-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:01:03,808 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:01:03,808-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:01:03,819 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-86c8f347-0148-4d73-a0c8-39307688a2af
2018-11-28 02:01:03,819-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-86c8f347-0148-4d73-a0c8-39307688a2af
2018-11-28 02:01:03,871 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:01:03,871-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:01:03,927 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:01:03,927-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:01:04,036 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @7150ms
2018-11-28 02:01:04,036-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @7150ms
2018-11-28 02:01:04,109 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:01:04,109-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:01:04,127 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @7242ms
2018-11-28 02:01:04,127-[TS] INFO main org.spark_project.jetty.server.Server - Started @7242ms
2018-11-28 02:01:04,150 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:01:04,150-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:01:04,150 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:01:04,150-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:01:04,172 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,172-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,173 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,173-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,174 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,174-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,175 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,175-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,175 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,175-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,176 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,176-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,176 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,176-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,177 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,177-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,178 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,178-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,178 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,178-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,179 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,179-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,179 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,179-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,180 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,180-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,180 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,180-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,181 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,181-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,181 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,181-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,182 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,182-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,182 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,182-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,183 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,183-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,184 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,184-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,192 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,192-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,193 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,193-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,194 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,194-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,195 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,195-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,196 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,196-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,198 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:01:04,198-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:01:04,298 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:01:04,298-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:01:04,326 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52651.
2018-11-28 02:01:04,326-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52651.
2018-11-28 02:01:04,327 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:52651
2018-11-28 02:01:04,327-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:52651
2018-11-28 02:01:04,329 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:01:04,329-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:01:04,368 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,368-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,374 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:52651 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,374-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:52651 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,377 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,377-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,378 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,378-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52651, None)
2018-11-28 02:01:04,589 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:04,589-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,245 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:01:06,245-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:01:06,246 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:01:06,246-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:01:06,254 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,254-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,255 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,255-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,256 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,256-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,256 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,256-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,258 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,258-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:01:06,855 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:01:06,855-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:01:07,103 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:01:07,103-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:01:07,438 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:01:07,438-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:01:07,449 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:01:07,449-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:01:15,050 [dispatcher-event-loop-5] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (116 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:01:15,050-[TS] WARN dispatcher-event-loop-5 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (116 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:04:48,445 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:04:48,445-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:04:48,962 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:04:48,962-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:04:54,148 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:04:54,148-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:04:54,163 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:04:54,163-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:04:54,163 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:04:54,163-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:04:54,164 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:04:54,164-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:04:54,164 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:04:54,164-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:04:54,165 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:04:54,165-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:04:54,384 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 52732.
2018-11-28 02:04:54,384-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52732.
2018-11-28 02:04:54,398 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:04:54,398-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:04:54,411 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:04:54,411-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:04:54,414 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:04:54,414-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:04:54,414 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:04:54,414-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:04:54,421 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-61366999-989b-463b-a09b-1f0685b023a0
2018-11-28 02:04:54,421-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-61366999-989b-463b-a09b-1f0685b023a0
2018-11-28 02:04:54,465 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:04:54,465-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:04:54,509 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:04:54,509-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:04:54,574 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6824ms
2018-11-28 02:04:54,574-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6824ms
2018-11-28 02:04:54,623 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:04:54,623-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:04:54,636 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6887ms
2018-11-28 02:04:54,636-[TS] INFO main org.spark_project.jetty.server.Server - Started @6887ms
2018-11-28 02:04:54,653 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@3f330f15{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:04:54,653-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@3f330f15{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:04:54,654 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:04:54,654-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:04:54,678 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,678-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,679 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,679-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,681 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,681-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,682 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,682-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,683 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,683-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,683 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,683-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,684 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,684-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,685 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,685-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,686 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,686-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,686 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,686-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,687 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,687-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,688 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,688-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,689 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,689-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,689 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,689-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,690 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,690-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,691 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,691-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,692 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,692-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,693 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,693-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,694 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,694-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,696 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,696-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,703 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,703-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,704 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,704-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,706 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,706-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,707 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,707-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,708 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,708-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:04:54,710 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:04:54,710-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:04:54,786 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:04:54,786-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:04:54,803 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52733.
2018-11-28 02:04:54,803-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52733.
2018-11-28 02:04:54,804 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:52733
2018-11-28 02:04:54,804-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:52733
2018-11-28 02:04:54,804 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:04:54,804-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:04:54,823 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,823-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,825 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:52733 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,825-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:52733 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,827 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,827-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,827 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:54,827-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52733, None)
2018-11-28 02:04:55,021 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:55,021-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,408 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:04:56,408-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:04:56,408 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:04:56,408-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:04:56,413 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,413-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,413 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,413-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,414 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,414-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,414 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,414-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,415 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,415-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:04:56,790 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:04:56,790-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:04:56,926 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:04:56,926-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:04:57,165 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:04:57,165-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:04:57,176 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:04:57,176-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:05:04,375 [dispatcher-event-loop-7] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (115 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:05:04,375-[TS] WARN dispatcher-event-loop-7 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (115 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:09:06,886 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:09:06,886-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:09:07,388 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:09:07,388-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:09:12,533 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:09:12,533-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:09:12,550 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:09:12,550-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:09:12,550 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:09:12,550-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:09:12,551 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:09:12,551-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:09:12,551 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:09:12,551-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:09:12,551 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:09:12,551-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:09:12,794 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 52784.
2018-11-28 02:09:12,794-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52784.
2018-11-28 02:09:12,810 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:09:12,810-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:09:12,826 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:09:12,826-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:09:12,828 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:09:12,828-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:09:12,828 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:09:12,828-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:09:12,835 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-1e80f013-6698-4d41-9238-b638ca656174
2018-11-28 02:09:12,835-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-1e80f013-6698-4d41-9238-b638ca656174
2018-11-28 02:09:12,884 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:09:12,884-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:09:12,953 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:09:12,953-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:09:13,073 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6927ms
2018-11-28 02:09:13,073-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6927ms
2018-11-28 02:09:13,142 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:09:13,142-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:09:13,157 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @7013ms
2018-11-28 02:09:13,157-[TS] INFO main org.spark_project.jetty.server.Server - Started @7013ms
2018-11-28 02:09:13,175 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@50e92c65{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:09:13,175-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@50e92c65{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:09:13,175 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:09:13,175-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:09:13,203 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,203-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,204 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,204-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,205 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,205-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,207 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,207-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,208 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,208-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,209 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,209-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,210 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,210-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,211 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,211-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,213 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,213-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,214 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,214-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,216 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,216-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,218 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,218-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,220 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,220-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,221 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,221-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,222 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,222-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,223 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,223-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,224 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,224-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,225 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,225-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,227 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,227-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,228 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,228-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,243 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,243-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,244 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,244-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,246 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,246-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,248 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,248-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,249 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,249-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,252 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:09:13,252-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:09:13,354 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:09:13,354-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:09:13,374 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52785.
2018-11-28 02:09:13,374-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52785.
2018-11-28 02:09:13,374 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:52785
2018-11-28 02:09:13,374-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:52785
2018-11-28 02:09:13,376 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:09:13,376-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:09:13,400 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,400-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,402 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:52785 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,402-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:52785 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,405 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,405-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,405 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,405-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52785, None)
2018-11-28 02:09:13,575 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:13,575-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,179 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:09:15,179-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:09:15,180 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:09:15,180-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:09:15,186 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,186-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,187 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,187-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,188 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,188-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,189 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,189-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,190 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,190-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:09:15,615 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:09:15,615-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:09:15,840 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:09:15,840-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:09:16,106 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:09:16,106-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:09:16,121 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:09:16,121-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:09:23,357 [dispatcher-event-loop-7] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (115 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:09:23,357-[TS] WARN dispatcher-event-loop-7 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (115 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:13:11,742 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:13:11,742-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:13:12,151 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:13:12,151-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:13:17,291 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:13:17,291-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:13:17,306 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:13:17,306-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:13:17,307 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:13:17,307-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:13:17,307 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:13:17,307-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:13:17,308 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:13:17,308-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:13:17,308 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:13:17,308-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:13:17,528 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 52870.
2018-11-28 02:13:17,528-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52870.
2018-11-28 02:13:17,542 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:13:17,542-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:13:17,555 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:13:17,555-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:13:17,557 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:13:17,557-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:13:17,558 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:13:17,558-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:13:17,565 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-c7a85b8e-0e9c-4af2-9173-db0035909f29
2018-11-28 02:13:17,565-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-c7a85b8e-0e9c-4af2-9173-db0035909f29
2018-11-28 02:13:17,609 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:13:17,609-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:13:17,651 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:13:17,651-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:13:17,714 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6644ms
2018-11-28 02:13:17,714-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6644ms
2018-11-28 02:13:17,762 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:13:17,762-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:13:17,773 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6704ms
2018-11-28 02:13:17,773-[TS] INFO main org.spark_project.jetty.server.Server - Started @6704ms
2018-11-28 02:13:17,790 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@2a8fe5c5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:13:17,790-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2a8fe5c5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:13:17,790 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:13:17,790-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:13:17,812 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,812-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,813 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,813-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,814 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,814-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,815 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,815-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,816 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,816-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,817 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,817-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,817 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,817-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,819 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,819-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,820 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,820-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,820 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,820-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,821 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,821-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,822 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,822-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,823 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,823-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,824 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,824-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,824 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,824-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,825 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,825-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,826 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,826-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,827 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,827-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,828 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,828-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,829 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,829-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,836 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,836-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,837 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,837-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,839 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,839-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,840 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,840-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,840 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,840-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:13:17,843 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:13:17,843-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:13:17,918 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:13:17,918-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:13:17,936 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52871.
2018-11-28 02:13:17,936-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52871.
2018-11-28 02:13:17,937 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:52871
2018-11-28 02:13:17,937-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:52871
2018-11-28 02:13:17,938 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:13:17,938-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:13:17,956 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,956-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,958 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:52871 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,958-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:52871 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,960 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,960-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,961 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:17,961-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52871, None)
2018-11-28 02:13:18,126 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:18,126-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,556 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:13:19,556-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:13:19,556 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:13:19,556-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:13:19,562 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,562-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,562 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,562-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,563 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,563-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,564 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,564-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,565 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,565-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:13:19,986 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:13:19,986-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:13:20,144 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:13:20,144-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:13:20,383 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:13:20,383-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:13:20,394 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:13:20,394-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:13:27,613 [dispatcher-event-loop-7] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (117 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:13:27,613-[TS] WARN dispatcher-event-loop-7 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (117 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:15:09,308 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:15:09,308-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:15:09,719 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:15:09,719-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:15:14,863 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:15:14,863-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:15:14,879 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:15:14,879-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:15:14,880 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:15:14,880-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:15:14,880 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:15:14,880-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:15:14,881 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:15:14,881-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:15:14,881 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:15:14,881-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:15:15,130 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 52930.
2018-11-28 02:15:15,130-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52930.
2018-11-28 02:15:15,146 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:15:15,146-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:15:15,161 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:15:15,161-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:15:15,163 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:15:15,163-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:15:15,164 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:15:15,164-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:15:15,171 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-5f6ac53e-ade5-4c26-80f0-910ccf7484cd
2018-11-28 02:15:15,171-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-5f6ac53e-ade5-4c26-80f0-910ccf7484cd
2018-11-28 02:15:15,215 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:15:15,215-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:15:15,268 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:15:15,268-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:15:15,344 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6703ms
2018-11-28 02:15:15,344-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6703ms
2018-11-28 02:15:15,400 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:15:15,400-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:15:15,413 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6774ms
2018-11-28 02:15:15,413-[TS] INFO main org.spark_project.jetty.server.Server - Started @6774ms
2018-11-28 02:15:15,432 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@74cec793{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:15:15,432-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@74cec793{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:15:15,432 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:15:15,432-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:15:15,455 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@319dead1{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,455-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@319dead1{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,456 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,456-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,457 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,457-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,458 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,458-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,459 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,459-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,459 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,459-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,460 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@cf65451{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,460-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@cf65451{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,462 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,462-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,462 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,462-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,463 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,463-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,463 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,463-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,465 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,465-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,466 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,466-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,467 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,467-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,468 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,468-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,469 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,469-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,469 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64712be{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,469-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64712be{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,470 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,470-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,470 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,470-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,471 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5ae81e1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,471-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae81e1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,480 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5ae76500{/static,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,480-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae76500{/static,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,481 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,481-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,483 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59aa20b3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,483-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59aa20b3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,483 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@19b30c92{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,483-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19b30c92{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,485 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@29876704{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,485-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@29876704{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,487 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:15:15,487-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:15:15,575 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:15:15,575-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:15:15,598 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52931.
2018-11-28 02:15:15,598-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52931.
2018-11-28 02:15:15,598 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:52931
2018-11-28 02:15:15,598-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:52931
2018-11-28 02:15:15,599 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:15:15,599-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:15:15,626 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,626-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,630 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:52931 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,630-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:52931 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,633 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,633-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,633 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,633-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52931, None)
2018-11-28 02:15:15,808 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3249a1ce{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:15,808-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3249a1ce{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,187 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:15:17,187-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:15:17,188 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:15:17,188-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:15:17,193 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,193-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,193 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2bbb44da{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,193-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2bbb44da{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,194 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,194-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,194 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4ef2ab73{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,194-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4ef2ab73{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,195 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1c33e528{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,195-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c33e528{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:15:17,600 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:15:17,600-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:15:17,775 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:15:17,775-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:15:18,035 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:15:18,035-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:15:18,048 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:15:18,048-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:15:25,453 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (115 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:15:25,453-[TS] WARN dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (115 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:17:37,600 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:17:37,600-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:17:38,040 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:17:38,040-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:17:43,195 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:17:43,195-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:17:43,210 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:17:43,210-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:17:43,211 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:17:43,211-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:17:43,211 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:17:43,211-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:17:43,212 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:17:43,212-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:17:43,212 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:17:43,212-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:17:43,442 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 52988.
2018-11-28 02:17:43,442-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 52988.
2018-11-28 02:17:43,456 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:17:43,456-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:17:43,470 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:17:43,470-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:17:43,472 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:17:43,472-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:17:43,473 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:17:43,473-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:17:43,479 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-1de0360e-da9f-4bab-81f8-e9b7157802ef
2018-11-28 02:17:43,479-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-1de0360e-da9f-4bab-81f8-e9b7157802ef
2018-11-28 02:17:43,520 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:17:43,520-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:17:43,561 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:17:43,561-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:17:43,652 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6717ms
2018-11-28 02:17:43,652-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6717ms
2018-11-28 02:17:43,706 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:17:43,706-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:17:43,720 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6787ms
2018-11-28 02:17:43,720-[TS] INFO main org.spark_project.jetty.server.Server - Started @6787ms
2018-11-28 02:17:43,738 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@3df0e45f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:17:43,738-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@3df0e45f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:17:43,739 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:17:43,739-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:17:43,766 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,766-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,766 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,766-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,767 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,767-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,768 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,768-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,769 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,769-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,769 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,769-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,770 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,770-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,772 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,772-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,773 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,773-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,774 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,774-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,775 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,775-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,775 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,775-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,776 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,776-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,777 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,777-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,777 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,777-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,778 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,778-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,779 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,779-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,780 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,780-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,781 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,781-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,781 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,781-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,787 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,787-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,788 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,788-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,789 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,789-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,790 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,790-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,791 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,791-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:17:43,793 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:17:43,793-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:17:43,875 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:17:43,875-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:17:43,899 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52989.
2018-11-28 02:17:43,899-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52989.
2018-11-28 02:17:43,899 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:52989
2018-11-28 02:17:43,899-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:52989
2018-11-28 02:17:43,901 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:17:43,901-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:17:43,929 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,929-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,933 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:52989 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,933-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:52989 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,935 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,935-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,936 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:43,936-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 52989, None)
2018-11-28 02:17:44,117 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:44,117-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,536 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:17:45,536-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:17:45,537 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:17:45,537-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:17:45,542 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,542-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6fcd31c3{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,542 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,542-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5503de1{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,543 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,543-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4816ee24{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,543 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,543-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73613ae5{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,544 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,544-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e09f1b6{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:17:45,938 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:17:45,938-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:17:46,094 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:17:46,094-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:17:46,330 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:17:46,330-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:17:46,343 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:17:46,343-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:17:53,542 [dispatcher-event-loop-7] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (111 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:17:53,542-[TS] WARN dispatcher-event-loop-7 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (111 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:20:36,125 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:20:36,125-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:20:36,588 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:20:36,588-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:20:41,752 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:20:41,752-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:20:41,768 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:20:41,768-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:20:41,769 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:20:41,769-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:20:41,769 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:20:41,769-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:20:41,770 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:20:41,770-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:20:41,770 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:20:41,770-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:20:41,990 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 53060.
2018-11-28 02:20:41,990-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53060.
2018-11-28 02:20:42,003 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:20:42,003-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:20:42,016 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:20:42,016-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:20:42,018 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:20:42,018-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:20:42,019 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:20:42,019-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:20:42,025 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-f35dd8fb-7ecb-40ba-b793-16d876705911
2018-11-28 02:20:42,025-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-f35dd8fb-7ecb-40ba-b793-16d876705911
2018-11-28 02:20:42,065 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:20:42,065-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:20:42,105 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:20:42,105-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:20:42,169 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6779ms
2018-11-28 02:20:42,169-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6779ms
2018-11-28 02:20:42,215 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:20:42,215-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:20:42,227 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6838ms
2018-11-28 02:20:42,227-[TS] INFO main org.spark_project.jetty.server.Server - Started @6838ms
2018-11-28 02:20:42,243 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:20:42,243-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:20:42,243 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:20:42,243-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:20:42,271 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,271-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,272 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,272-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,273 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,273-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,274 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,274-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,275 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,275-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,276 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,276-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,277 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,277-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,279 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,279-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,279 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,279-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,280 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,280-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,281 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,281-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,282 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,282-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,282 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,282-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,283 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,283-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,284 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,284-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,285 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,285-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,286 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,286-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,287 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,287-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,288 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,288-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,289 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,289-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,298 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,298-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,300 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,300-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,303 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,303-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,304 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,304-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,304 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,304-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,306 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:20:42,306-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:20:42,388 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:20:42,388-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:20:42,405 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53061.
2018-11-28 02:20:42,405-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53061.
2018-11-28 02:20:42,406 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:53061
2018-11-28 02:20:42,406-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:53061
2018-11-28 02:20:42,407 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:20:42,407-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:20:42,427 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,427-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,430 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:53061 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,430-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:53061 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,433 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,433-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,433 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,433-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53061, None)
2018-11-28 02:20:42,593 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:42,593-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,005 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:20:44,005-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:20:44,005 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:20:44,005-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:20:44,011 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,011-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67bf0480{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,012 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,012-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32faa16c{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,012 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,012-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20d33ea{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,013 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,013-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a13fcf3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,014 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,014-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@557b6a37{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:20:44,480 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:20:44,480-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:20:44,650 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:20:44,650-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:20:44,904 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:20:44,904-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:20:44,919 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:20:44,919-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:20:52,440 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (113 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:20:52,440-[TS] WARN dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (113 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:23:15,571 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:23:15,571-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:23:16,042 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:23:16,042-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:23:21,183 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:23:21,183-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:23:21,198 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:23:21,198-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:23:21,199 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:23:21,199-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:23:21,199 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:23:21,199-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:23:21,199 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:23:21,199-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:23:21,200 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:23:21,200-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:23:21,417 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 53112.
2018-11-28 02:23:21,417-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53112.
2018-11-28 02:23:21,432 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:23:21,432-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:23:21,445 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:23:21,445-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:23:21,447 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:23:21,447-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:23:21,448 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:23:21,448-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:23:21,455 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-b9cfc60a-ebdd-4a8c-aa23-c6d9496edd1e
2018-11-28 02:23:21,455-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-b9cfc60a-ebdd-4a8c-aa23-c6d9496edd1e
2018-11-28 02:23:21,498 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:23:21,498-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:23:21,542 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:23:21,542-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:23:21,611 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6704ms
2018-11-28 02:23:21,611-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6704ms
2018-11-28 02:23:21,663 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:23:21,663-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:23:21,676 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6770ms
2018-11-28 02:23:21,676-[TS] INFO main org.spark_project.jetty.server.Server - Started @6770ms
2018-11-28 02:23:21,694 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:23:21,694-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:23:21,695 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:23:21,695-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:23:21,719 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,719-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,721 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,721-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,721 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,721-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,723 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,723-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,724 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,724-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,725 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,725-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,727 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,727-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,728 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,728-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,729 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,729-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,729 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,729-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,730 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,730-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,731 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,731-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,732 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,732-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,732 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,732-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,733 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,733-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,734 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,734-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,735 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,735-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,736 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,736-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,737 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,737-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,744 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,744-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,745 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,745-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,746 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,746-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,748 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,748-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,748 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,748-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:23:21,750 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:23:21,750-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:23:21,824 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:23:21,824-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:23:21,842 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53113.
2018-11-28 02:23:21,842-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53113.
2018-11-28 02:23:21,842 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:53113
2018-11-28 02:23:21,842-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:53113
2018-11-28 02:23:21,843 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:23:21,843-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:23:21,862 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,862-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,865 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:53113 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,865-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:53113 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,867 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,867-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,867 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:21,867-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53113, None)
2018-11-28 02:23:22,027 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:22,027-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,414 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:23:23,414-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:23:23,414 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:23:23,414-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:23:23,419 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,419-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,420 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,420-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,420 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,420-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,420 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,420-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,421 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,421-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:23:23,853 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:23:23,853-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:23:23,996 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:23:23,996-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:23:24,205 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:23:24,205-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:23:24,220 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:23:24,220-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:23:31,337 [dispatcher-event-loop-7] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (112 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:23:31,337-[TS] WARN dispatcher-event-loop-7 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (112 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:24:42,206 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:24:42,206-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:24:42,626 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:24:42,626-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:24:47,774 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:24:47,774-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:24:47,789 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:24:47,789-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:24:47,790 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:24:47,790-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:24:47,790 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:24:47,790-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:24:47,790 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:24:47,790-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:24:47,791 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:24:47,791-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:24:48,041 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 53156.
2018-11-28 02:24:48,041-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53156.
2018-11-28 02:24:48,054 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:24:48,054-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:24:48,068 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:24:48,068-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:24:48,071 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:24:48,071-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:24:48,071 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:24:48,071-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:24:48,077 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-425ea9a5-9693-4561-a7d1-8a12e983fcb7
2018-11-28 02:24:48,077-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-425ea9a5-9693-4561-a7d1-8a12e983fcb7
2018-11-28 02:24:48,120 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:24:48,120-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:24:48,162 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:24:48,162-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:24:48,229 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6762ms
2018-11-28 02:24:48,229-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6762ms
2018-11-28 02:24:48,279 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:24:48,279-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:24:48,291 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6825ms
2018-11-28 02:24:48,291-[TS] INFO main org.spark_project.jetty.server.Server - Started @6825ms
2018-11-28 02:24:48,309 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@5a6b5209{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:24:48,309-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@5a6b5209{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:24:48,310 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:24:48,310-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:24:48,333 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,333-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,334 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,334-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,335 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,335-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,336 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,336-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,337 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,337-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,337 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,337-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,338 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,338-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,340 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,340-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,341 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,341-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,342 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,342-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,343 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,343-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,344 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,344-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,344 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,344-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,345 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,345-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,346 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,346-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,348 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,348-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,349 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,349-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,351 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,351-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,352 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,352-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,353 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,353-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,364 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,364-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,365 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,365-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,368 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,368-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,369 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,369-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,371 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,371-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,374 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:24:48,374-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:24:48,461 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:24:48,461-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:24:48,479 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53157.
2018-11-28 02:24:48,479-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53157.
2018-11-28 02:24:48,480 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:53157
2018-11-28 02:24:48,480-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:53157
2018-11-28 02:24:48,481 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:24:48,481-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:24:48,503 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,503-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,506 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:53157 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,506-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:53157 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,509 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,509-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,509 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,509-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53157, None)
2018-11-28 02:24:48,680 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:48,680-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,194 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:24:50,194-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:24:50,195 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:24:50,195-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:24:50,202 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,202-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,202 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,202-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,204 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,204-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,204 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,204-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,206 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,206-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:24:50,594 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:24:50,594-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:24:50,738 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:24:50,738-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:24:51,007 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:24:51,007-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:24:51,019 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:24:51,019-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:24:58,443 [dispatcher-event-loop-4] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:24:58,443-[TS] WARN dispatcher-event-loop-4 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (108 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:37:23,834 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:37:23,834-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:37:24,350 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:37:24,350-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:37:29,527 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:37:29,527-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:37:29,550 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:37:29,550-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:37:29,551 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:37:29,551-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:37:29,551 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:37:29,551-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:37:29,551 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:37:29,551-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:37:29,552 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:37:29,552-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:37:29,881 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 53418.
2018-11-28 02:37:29,881-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53418.
2018-11-28 02:37:29,907 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:37:29,907-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:37:29,931 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:37:29,931-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:37:29,935 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:37:29,935-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:37:29,936 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:37:29,936-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:37:29,948 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-d9ee96f0-759d-492e-a7b1-cef7ad96599d
2018-11-28 02:37:29,948-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-d9ee96f0-759d-492e-a7b1-cef7ad96599d
2018-11-28 02:37:30,001 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:37:30,001-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:37:30,055 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:37:30,055-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:37:30,162 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @7044ms
2018-11-28 02:37:30,162-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @7044ms
2018-11-28 02:37:30,236 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:37:30,236-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:37:30,253 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @7136ms
2018-11-28 02:37:30,253-[TS] INFO main org.spark_project.jetty.server.Server - Started @7136ms
2018-11-28 02:37:30,275 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:37:30,275-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@18e7143f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:37:30,275 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:37:30,275-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:37:30,298 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,298-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@523424b5{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,299 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,299-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66971f6b{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,300 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,300-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@517bd097{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,301 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,301-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5990e6c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,301 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,301-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d6ca49{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,302 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,302-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47289387{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,302 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,302-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@114a85c2{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,304 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,304-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@37eeec90{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,305 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,305-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c9413d8{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,306 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,306-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46074492{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,306 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,306-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c715e84{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,307 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,307-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3b9d6699{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,307 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,307-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21694e53{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,308 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,308-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22c86919{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,309 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,309-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b0a7baf{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,309 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,309-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32057e6{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,310 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,310-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ea1bcdc{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,311 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,311-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64712be{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,312 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,312-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30ed9c6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,313 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,313-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46c670a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,321 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,321-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae81e1{/static,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,322 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,322-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ec5d87{/,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,323 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,323-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@552518c3{/api,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,323 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,323-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@138fe6ec{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,324 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,324-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19b30c92{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,326 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:37:30,326-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:37:30,425 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:37:30,425-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:37:30,449 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53419.
2018-11-28 02:37:30,449-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53419.
2018-11-28 02:37:30,449 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:53419
2018-11-28 02:37:30,449-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:53419
2018-11-28 02:37:30,451 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:37:30,451-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:37:30,485 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,485-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,489 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:53419 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,489-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:53419 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,492 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,492-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,493 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,493-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53419, None)
2018-11-28 02:37:30,722 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:30,722-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@497570fb{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,289 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:37:32,289-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:37:32,290 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:37:32,290-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:37:32,299 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,299-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ab24484{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,300 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,300-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@106b014e{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,301 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,301-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@662e682a{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,302 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,302-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@649f25f3{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,304 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,304-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f18e31{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:37:32,733 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:37:32,733-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:37:32,881 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:37:32,881-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:37:33,171 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:37:33,171-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:37:33,183 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:37:33,183-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:37:40,459 [dispatcher-event-loop-7] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 0 contains a task of very large size (104 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:37:40,459-[TS] WARN dispatcher-event-loop-7 org.apache.spark.scheduler.TaskSetManager - Stage 0 contains a task of very large size (104 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:37:43,701 [Executor task launch worker for task 1002] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 23.0 in stage 11.0 (TID 1002)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,701-[TS] ERROR Executor task launch worker for task 1002 org.apache.spark.executor.Executor - Exception in task 23.0 in stage 11.0 (TID 1002)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,707 [Executor task launch worker for task 1003] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 27.0 in stage 11.0 (TID 1003)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,707-[TS] ERROR Executor task launch worker for task 1003 org.apache.spark.executor.Executor - Exception in task 27.0 in stage 11.0 (TID 1003)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,705 [Executor task launch worker for task 1006] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 77.0 in stage 11.0 (TID 1006)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,705-[TS] ERROR Executor task launch worker for task 1006 org.apache.spark.executor.Executor - Exception in task 77.0 in stage 11.0 (TID 1006)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,703 [Executor task launch worker for task 1007] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 101.0 in stage 11.0 (TID 1007)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,703-[TS] ERROR Executor task launch worker for task 1007 org.apache.spark.executor.Executor - Exception in task 101.0 in stage 11.0 (TID 1007)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,709 [Executor task launch worker for task 1005] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 55.0 in stage 11.0 (TID 1005)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,709-[TS] ERROR Executor task launch worker for task 1005 org.apache.spark.executor.Executor - Exception in task 55.0 in stage 11.0 (TID 1005)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,712 [Executor task launch worker for task 1004] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 54.0 in stage 11.0 (TID 1004)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,712-[TS] ERROR Executor task launch worker for task 1004 org.apache.spark.executor.Executor - Exception in task 54.0 in stage 11.0 (TID 1004)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,723 [Executor task launch worker for task 1009] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 136.0 in stage 11.0 (TID 1009)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,723-[TS] ERROR Executor task launch worker for task 1009 org.apache.spark.executor.Executor - Exception in task 136.0 in stage 11.0 (TID 1009)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,724 [Executor task launch worker for task 1008] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 119.0 in stage 11.0 (TID 1008)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,724-[TS] ERROR Executor task launch worker for task 1008 org.apache.spark.executor.Executor - Exception in task 119.0 in stage 11.0 (TID 1008)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,732 [task-result-getter-0] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Lost task 119.0 in stage 11.0 (TID 1008, localhost, executor driver): java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-11-28 02:37:43,732-[TS] WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 119.0 in stage 11.0 (TID 1008, localhost, executor driver): java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-11-28 02:37:43,735 [task-result-getter-0] [org.apache.spark.scheduler.TaskSetManager] [ERROR] - Task 119 in stage 11.0 failed 1 times; aborting job
2018-11-28 02:37:43,735-[TS] ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 119 in stage 11.0 failed 1 times; aborting job
2018-11-28 02:37:43,736 [Executor task launch worker for task 1013] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 154.0 in stage 11.0 (TID 1013)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,736-[TS] ERROR Executor task launch worker for task 1013 org.apache.spark.executor.Executor - Exception in task 154.0 in stage 11.0 (TID 1013)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,736 [Executor task launch worker for task 1014] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 172.0 in stage 11.0 (TID 1014)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,736-[TS] ERROR Executor task launch worker for task 1014 org.apache.spark.executor.Executor - Exception in task 172.0 in stage 11.0 (TID 1014)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,739 [Executor task launch worker for task 1012] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 150.0 in stage 11.0 (TID 1012)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,739-[TS] ERROR Executor task launch worker for task 1012 org.apache.spark.executor.Executor - Exception in task 150.0 in stage 11.0 (TID 1012)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,742 [Executor task launch worker for task 1010] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 143.0 in stage 11.0 (TID 1010)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,742-[TS] ERROR Executor task launch worker for task 1010 org.apache.spark.executor.Executor - Exception in task 143.0 in stage 11.0 (TID 1010)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,745 [Executor task launch worker for task 1011] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 146.0 in stage 11.0 (TID 1011)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,745-[TS] ERROR Executor task launch worker for task 1011 org.apache.spark.executor.Executor - Exception in task 146.0 in stage 11.0 (TID 1011)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,745 [Executor task launch worker for task 1015] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 188.0 in stage 11.0 (TID 1015)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:37:43,745-[TS] ERROR Executor task launch worker for task 1015 org.apache.spark.executor.Executor - Exception in task 188.0 in stage 11.0 (TID 1015)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to java.lang.Double
	at scala.runtime.BoxesRunTime.unboxToDouble(BoxesRunTime.java:114)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:53)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:29,019 [main] [org.apache.spark.SparkContext] [INFO] - Running Spark version 2.2.2
2018-11-28 02:42:29,019-[TS] INFO main org.apache.spark.SparkContext - Running Spark version 2.2.2
2018-11-28 02:42:29,455 [main] [org.apache.hadoop.util.NativeCodeLoader] [WARN] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:42:29,455-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-11-28 02:42:34,592 [main] [org.apache.spark.SparkContext] [INFO] - Submitted application: UserSessionAnasysJob$
2018-11-28 02:42:34,592-[TS] INFO main org.apache.spark.SparkContext - Submitted application: UserSessionAnasysJob$
2018-11-28 02:42:34,607 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls to: newforesee
2018-11-28 02:42:34,607-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls to: newforesee
2018-11-28 02:42:34,607 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls to: newforesee
2018-11-28 02:42:34,607-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls to: newforesee
2018-11-28 02:42:34,608 [main] [org.apache.spark.SecurityManager] [INFO] - Changing view acls groups to: 
2018-11-28 02:42:34,608-[TS] INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
2018-11-28 02:42:34,608 [main] [org.apache.spark.SecurityManager] [INFO] - Changing modify acls groups to: 
2018-11-28 02:42:34,608-[TS] INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
2018-11-28 02:42:34,609 [main] [org.apache.spark.SecurityManager] [INFO] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:42:34,609-[TS] INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(newforesee); groups with view permissions: Set(); users  with modify permissions: Set(newforesee); groups with modify permissions: Set()
2018-11-28 02:42:34,827 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'sparkDriver' on port 53568.
2018-11-28 02:42:34,827-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 53568.
2018-11-28 02:42:34,844 [main] [org.apache.spark.SparkEnv] [INFO] - Registering MapOutputTracker
2018-11-28 02:42:34,844-[TS] INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
2018-11-28 02:42:34,857 [main] [org.apache.spark.SparkEnv] [INFO] - Registering BlockManagerMaster
2018-11-28 02:42:34,857-[TS] INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
2018-11-28 02:42:34,859 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:42:34,859-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-28 02:42:34,860 [main] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - BlockManagerMasterEndpoint up
2018-11-28 02:42:34,860-[TS] INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-11-28 02:42:34,866 [main] [org.apache.spark.storage.DiskBlockManager] [INFO] - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-3312e148-89ec-4915-a6e9-2ca06a4febda
2018-11-28 02:42:34,866-[TS] INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/gw/182hsxpd1l78ny7x0627rr1m0000gn/T/blockmgr-3312e148-89ec-4915-a6e9-2ca06a4febda
2018-11-28 02:42:34,912 [main] [org.apache.spark.storage.memory.MemoryStore] [INFO] - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:42:34,912-[TS] INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1458.6 MB
2018-11-28 02:42:34,956 [main] [org.apache.spark.SparkEnv] [INFO] - Registering OutputCommitCoordinator
2018-11-28 02:42:34,956-[TS] INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2018-11-28 02:42:35,135 [main] [org.spark_project.jetty.util.log] [INFO] - Logging initialized @6757ms
2018-11-28 02:42:35,135-[TS] INFO main org.spark_project.jetty.util.log - Logging initialized @6757ms
2018-11-28 02:42:35,180 [main] [org.spark_project.jetty.server.Server] [INFO] - jetty-9.3.z-SNAPSHOT
2018-11-28 02:42:35,180-[TS] INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
2018-11-28 02:42:35,191 [main] [org.spark_project.jetty.server.Server] [INFO] - Started @6815ms
2018-11-28 02:42:35,191-[TS] INFO main org.spark_project.jetty.server.Server - Started @6815ms
2018-11-28 02:42:35,207 [main] [org.spark_project.jetty.server.AbstractConnector] [INFO] - Started ServerConnector@3f330f15{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:42:35,207-[TS] INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@3f330f15{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-11-28 02:42:35,207 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:42:35,207-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2018-11-28 02:42:35,226 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,226-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bde62ff{/jobs,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,227 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,227-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3bffddff{/jobs/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,228 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,228-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50687efb{/jobs/job,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,229 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,229-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56e07a08{/stages,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,230 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,230-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1950e8a6{/stages/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,231 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,231-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@12cd9150{/stages/stage,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,232 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,232-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@724f138e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,233 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,233-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32fe9d0a{/stages/pool,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,233 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,233-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@64da2a7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,234 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,234-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d78795{/storage,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,235 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,235-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@47428937{/storage/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,235 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,235-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7caa550{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,236 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,236-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72b16078{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,237 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,237-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70fab835{/environment,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,238 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,238-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62417a16{/environment/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,239 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,239-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26be6ca7{/executors,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,239 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,239-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@759fad4{/executors/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,240 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,240-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53499d85{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,241 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,241-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@782a4fff{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,248 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,248-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59fc684e{/static,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,249 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,249-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1eba372c{/,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,250 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,250-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f9407e{/api,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,251 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,251-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b28f282{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,252 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,252-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5e77f0f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,253 [main] [org.apache.spark.ui.SparkUI] [INFO] - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:42:35,253-[TS] INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.106:4040
2018-11-28 02:42:35,323 [main] [org.apache.spark.executor.Executor] [INFO] - Starting executor ID driver on host localhost
2018-11-28 02:42:35,323-[TS] INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
2018-11-28 02:42:35,341 [main] [org.apache.spark.util.Utils] [INFO] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53569.
2018-11-28 02:42:35,341-[TS] INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53569.
2018-11-28 02:42:35,342 [main] [org.apache.spark.network.netty.NettyBlockTransferService] [INFO] - Server created on 192.168.0.106:53569
2018-11-28 02:42:35,342-[TS] INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.106:53569
2018-11-28 02:42:35,343 [main] [org.apache.spark.storage.BlockManager] [INFO] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:42:35,343-[TS] INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-28 02:42:35,364 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,364-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,367 [dispatcher-event-loop-2] [org.apache.spark.storage.BlockManagerMasterEndpoint] [INFO] - Registering block manager 192.168.0.106:53569 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,367-[TS] INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.106:53569 with 1458.6 MB RAM, BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,369 [main] [org.apache.spark.storage.BlockManagerMaster] [INFO] - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,369-[TS] INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,370 [main] [org.apache.spark.storage.BlockManager] [INFO] - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,370-[TS] INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.106, 53569, None)
2018-11-28 02:42:35,559 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:35,559-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b9eadd{/metrics/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,930 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:42:36,930-[TS] INFO main org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse').
2018-11-28 02:42:36,930 [main] [org.apache.spark.sql.internal.SharedState] [INFO] - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:42:36,930-[TS] INFO main org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/newforesee/Intellij%20Project/SparkLog/spark-warehouse'.
2018-11-28 02:42:36,935 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,935-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6963b88c{/SQL,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,936 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,936-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54e43bfe{/SQL/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,936 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,936-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41d16cc3{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,937 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,937-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e43c38d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,938 [main] [org.spark_project.jetty.server.handler.ContextHandler] [INFO] - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:42:36,938-[TS] INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fd72332{/static/sql,null,AVAILABLE,@Spark}
2018-11-28 02:42:37,313 [main] [org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef] [INFO] - Registered StateStoreCoordinator endpoint
2018-11-28 02:42:37,313-[TS] INFO main org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
2018-11-28 02:42:37,455 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_visit_action
2018-11-28 02:42:37,455-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_visit_action
2018-11-28 02:42:37,689 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: user_info
2018-11-28 02:42:37,689-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: user_info
2018-11-28 02:42:37,702 [main] [org.apache.spark.sql.execution.SparkSqlParser] [INFO] - Parsing command: product_info
2018-11-28 02:42:37,702-[TS] INFO main org.apache.spark.sql.execution.SparkSqlParser - Parsing command: product_info
2018-11-28 02:42:45,084 [dispatcher-event-loop-3] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Stage 1 contains a task of very large size (106 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:42:45,084-[TS] WARN dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Stage 1 contains a task of very large size (106 KB). The maximum recommended task size is 100 KB.
2018-11-28 02:42:48,084 [Executor task launch worker for task 999] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 77.0 in stage 11.0 (TID 999)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 999 org.apache.spark.executor.Executor - Exception in task 77.0 in stage 11.0 (TID 999)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,085 [Executor task launch worker for task 1000] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 101.0 in stage 11.0 (TID 1000)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,085-[TS] ERROR Executor task launch worker for task 1000 org.apache.spark.executor.Executor - Exception in task 101.0 in stage 11.0 (TID 1000)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084 [Executor task launch worker for task 994] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 23.0 in stage 11.0 (TID 994)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 994 org.apache.spark.executor.Executor - Exception in task 23.0 in stage 11.0 (TID 994)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084 [Executor task launch worker for task 998] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 55.0 in stage 11.0 (TID 998)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 998 org.apache.spark.executor.Executor - Exception in task 55.0 in stage 11.0 (TID 998)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084 [Executor task launch worker for task 995] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 27.0 in stage 11.0 (TID 995)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 995 org.apache.spark.executor.Executor - Exception in task 27.0 in stage 11.0 (TID 995)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084 [Executor task launch worker for task 1001] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 108.0 in stage 11.0 (TID 1001)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 1001 org.apache.spark.executor.Executor - Exception in task 108.0 in stage 11.0 (TID 1001)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084 [Executor task launch worker for task 997] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 54.0 in stage 11.0 (TID 997)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 997 org.apache.spark.executor.Executor - Exception in task 54.0 in stage 11.0 (TID 997)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084 [Executor task launch worker for task 996] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 47.0 in stage 11.0 (TID 996)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,084-[TS] ERROR Executor task launch worker for task 996 org.apache.spark.executor.Executor - Exception in task 47.0 in stage 11.0 (TID 996)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,101 [task-result-getter-0] [org.apache.spark.scheduler.TaskSetManager] [WARN] - Lost task 101.0 in stage 11.0 (TID 1000, localhost, executor driver): java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-11-28 02:42:48,101-[TS] WARN task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Lost task 101.0 in stage 11.0 (TID 1000, localhost, executor driver): java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

2018-11-28 02:42:48,105 [task-result-getter-0] [org.apache.spark.scheduler.TaskSetManager] [ERROR] - Task 101 in stage 11.0 failed 1 times; aborting job
2018-11-28 02:42:48,105-[TS] ERROR task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Task 101 in stage 11.0 failed 1 times; aborting job
2018-11-28 02:42:48,105 [Executor task launch worker for task 1005] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 136.0 in stage 11.0 (TID 1005)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,105-[TS] ERROR Executor task launch worker for task 1005 org.apache.spark.executor.Executor - Exception in task 136.0 in stage 11.0 (TID 1005)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,106 [Executor task launch worker for task 1009] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 146.0 in stage 11.0 (TID 1009)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,106-[TS] ERROR Executor task launch worker for task 1009 org.apache.spark.executor.Executor - Exception in task 146.0 in stage 11.0 (TID 1009)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,107 [Executor task launch worker for task 1003] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 119.0 in stage 11.0 (TID 1003)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,107-[TS] ERROR Executor task launch worker for task 1003 org.apache.spark.executor.Executor - Exception in task 119.0 in stage 11.0 (TID 1003)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,107 [Executor task launch worker for task 1004] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 125.0 in stage 11.0 (TID 1004)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,107-[TS] ERROR Executor task launch worker for task 1004 org.apache.spark.executor.Executor - Exception in task 125.0 in stage 11.0 (TID 1004)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,107 [Executor task launch worker for task 1007] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 139.0 in stage 11.0 (TID 1007)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,107-[TS] ERROR Executor task launch worker for task 1007 org.apache.spark.executor.Executor - Exception in task 139.0 in stage 11.0 (TID 1007)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,109 [Executor task launch worker for task 1006] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 138.0 in stage 11.0 (TID 1006)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,109-[TS] ERROR Executor task launch worker for task 1006 org.apache.spark.executor.Executor - Exception in task 138.0 in stage 11.0 (TID 1006)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,109 [Executor task launch worker for task 1008] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 143.0 in stage 11.0 (TID 1008)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,109-[TS] ERROR Executor task launch worker for task 1008 org.apache.spark.executor.Executor - Exception in task 143.0 in stage 11.0 (TID 1008)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,109 [Executor task launch worker for task 1002] [org.apache.spark.executor.Executor] [ERROR] - Exception in task 114.0 in stage 11.0 (TID 1002)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-11-28 02:42:48,109-[TS] ERROR Executor task launch worker for task 1002 org.apache.spark.executor.Executor - Exception in task 114.0 in stage 11.0 (TID 1002)
java.lang.NullPointerException
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:135)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:632)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:57)
	at top.newforesee.jobs.sessions.UserSessionAnasysJob$$anonfun$main$1.apply(UserSessionAnasysJob.scala:49)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.rdd.RDD$$anonfun$foreach$1$$anonfun$apply$28.apply(RDD.scala:918)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
